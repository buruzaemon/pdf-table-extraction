{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8654c4d9-80f4-4f4e-86b9-cc7fda2c72cc",
   "metadata": {},
   "source": [
    "# Google's Gemini 2.0 \n",
    "\n",
    "## ... ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a708161-6d5c-4d4b-b71a-ac6884fdd8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d86de69-c245-4337-b9c4-1dca6caa6335",
   "metadata": {},
   "source": [
    "## hello, world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c78adb0f-63e2-44a8-a8b0-e849d5abdba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4255092-c01e-4846-8f2a-c0ef40e2ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client\n",
    "api_key = \"AIzaSyDsYsuF_ObXDTA661hZmuy6RoNXV7ZglvU\"\n",
    "client = genai.Client(api_key=api_key)\n",
    " \n",
    "# Define the model you are going to use\n",
    "model_id =  \"gemini-2.0-flash\" # or \"gemini-2.0-flash-lite-preview-02-05\"  , \"gemini-2.0-pro-exp-02-05\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39198fb5-b023-437f-87ce-8b5400c30d3c",
   "metadata": {},
   "source": [
    "#### Prepare/upload PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2d0aa3-3917-4302-bdb9-44f085da10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_pdf = client.files.upload(\n",
    "    file=\"samples/saintmarc-hd_20250313.pdf\", \n",
    "    config={'display_name': '2025-Mar-borked'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06dbf5c7-4910-4b2b-b5ad-d42989cb9d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 2025-Mar-borked contains 259 tokens\n"
     ]
    }
   ],
   "source": [
    "file_size = client.models.count_tokens(\n",
    "    model=model_id,\n",
    "    contents=invoice_pdf\n",
    ")\n",
    "\n",
    "print(f'File: {invoice_pdf.display_name} contains {file_size.total_tokens} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859b5de-a49e-43eb-9af9-6887619b397d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17820961-ad06-421a-a670-1aab6b0a11ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"first_name\": \"Donald\",\n",
      "  \"last_name\": \"Trump\",\n",
      "  \"age\": 0,\n",
      "  \"work_topics\": []\n",
      "}\n",
      "First name is Donald\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    " \n",
    "# Define a Pydantic model\n",
    "# Use the Field class to add a description and default value to provide more context to the model\n",
    "class Topic(BaseModel):\n",
    "    name: str = Field(description=\"The name of the topic\")\n",
    " \n",
    "class Person(BaseModel):\n",
    "    first_name: str = Field(description=\"The first name of the person\")\n",
    "    last_name: str = Field(description=\"The last name of the person\")\n",
    "    age: int = Field(description=\"The age of the person, if not provided please return 0\")\n",
    "    work_topics: list[Topic] = Field(description=\"The fields of interest of the person, if not provided please return an empty list\")\n",
    " \n",
    " \n",
    "# Define the prompt\n",
    "prompt = \"Donald J. Trump is the 47th President of the United States of America. He is also an idiot and a coward.  \"\n",
    " \n",
    "# Generate a response using the Person model\n",
    "response = client.models.generate_content(\n",
    "    model=model_id, \n",
    "    contents=prompt, \n",
    "    config={\n",
    "        'response_mime_type': 'application/json', \n",
    "        'response_schema': Person\n",
    "})\n",
    " \n",
    "# print the response as a json string\n",
    "print(response.text)\n",
    " \n",
    "# sdk automatically converts the response to the pydantic model\n",
    "theDon: Person = response.parsed\n",
    " \n",
    "# access an attribute of the json response\n",
    "print(f\"First name is {theDon.first_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f0923-e8c1-43bd-bf57-bfef77a3e0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccb7e32c-2e33-4e37-9f27-791b92a95267",
   "metadata": {},
   "source": [
    "## 4. Extract Structured data from PDFs using Gemini 2.0\n",
    "\n",
    "Now, let's combine the File API and structured output to extract information from our PDFs. You can create a simple method that accepts a local file path and a pydantic model and return the structured data for us. The method will:\n",
    "\n",
    "1. Upload the file to the File API\n",
    "2. Generate a structured response using the Gemini API\n",
    "3. Convert the response to the pydantic model and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0285cd97-bcfc-46ba-b99d-a63858df5f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structured_data(file_path: str, model: BaseModel):\n",
    "    \n",
    "    # Upload the file to the File API\n",
    "    file = client.files.upload(\n",
    "        file=file_path, \n",
    "        config={\n",
    "            'display_name': file_path.split('/')[-1].split('.')[0]\n",
    "    })\n",
    "    \n",
    "    # Generate a structured response using the Gemini API\n",
    "    prompt = f\"Extract the structured data from the following PDF file\"\n",
    "    response = client.models.generate_content(\n",
    "        model=model_id, \n",
    "        contents=[prompt, file], \n",
    "        config={\n",
    "            'response_mime_type': 'application/json', \n",
    "            'response_schema': model\n",
    "    })\n",
    "    \n",
    "    # Convert the response to the pydantic model and return it\n",
    "    return response.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a936b-af6d-4602-ba4b-5ece15c07861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb079b40-ce84-423e-bd76-9ed64fa9d6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfca0d3-01b5-48c2-9fa5-f8d7fb145be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
